[2021-09-28 16:49:05,265] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2021-09-28 16:49:06,916] [INFO] [runner.py:360:main] cmd = /dataset/lichunyou/conda_env/miniconda3/envs/p7/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=59431 finetune_glm.py --deepspeed --deepspeed_config config_tasks/config_blocklm_10B.json --finetune --cloze-eval --experiment-name blank-base-copa_09-28-16-49 --task COPA --data-dir /dataset/lichunyou/GLM/GLM_copa/dataset/COPA --save /dataset/lichunyou/GLM/GLM_copa/copa_model --seq-length 256 --checkpoint-activations --eval-batch-size 4 --save-epoch 100000 --num-workers 1 --no-load-optim --no-load-lr-scheduler --block-lm --num-layers 12 --hidden-size 768 --num-attention-heads 12 --max-position-embeddings 512 --tokenizer-model-type bert-base-uncased --tokenizer-type BertWordPieceTokenizer --load-pretrained /dataset/lichunyou/GLM/GLM_copa/copa_model/blank-base-copa_08-25-23-55 --lr-decay-style linear --warmup 0.1 --weight-decay 1.0e-1 --pattern-id 0 --save-interval 10000 --log-interval 20 --eval-interval 1000 --eval-iters 100 --pattern-id 0 --fp16 --model-parallel-size 1 --epochs -1 --overwrite
[2021-09-28 16:49:08,292] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE 0
[2021-09-28 16:49:08,292] [INFO] [launch.py:73:main] 0 NCCL_DEBUG info
[2021-09-28 16:49:08,292] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL 2
[2021-09-28 16:49:08,292] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}
[2021-09-28 16:49:08,292] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0
[2021-09-28 16:49:08,292] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2021-09-28 16:49:08,293] [INFO] [launch.py:102:main] dist_world_size=1
[2021-09-28 16:49:08,293] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0
using world size: 1 and model-parallel size: 1 
 > using dynamic loss scaling
oneflow-22:2652666:2652666 [0] NCCL INFO Bootstrap : Using [0]eno1:192.168.1.22<0> [1]veth8a96493:fe80::a405:1cff:fed9:b8eb%veth8a96493<0> [2]veth2939e96:fe80::9c62:fbff:fe29:7ce1%veth2939e96<0>
oneflow-22:2652666:2652666 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
oneflow-22:2652666:2652666 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
oneflow-22:2652666:2652666 [0] NCCL INFO NET/IB : Using [0]iwo1:1/RoCE ; OOB eno1:192.168.1.22<0>
oneflow-22:2652666:2652666 [0] NCCL INFO Using network IB
NCCL version 2.7.8+cuda10.2
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 00/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 01/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 02/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 03/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 04/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 05/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 06/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 07/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 08/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 09/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 10/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 11/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 12/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 13/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 14/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 15/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 16/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 17/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 18/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 19/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 20/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 21/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 22/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 23/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 24/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 25/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 26/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 27/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 28/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 29/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 30/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Channel 31/32 :    0
oneflow-22:2652666:2653251 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1-
oneflow-22:2652666:2653251 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,ffff0000
oneflow-22:2652666:2653251 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
oneflow-22:2652666:2653251 [0] NCCL INFO comm 0x7f2ec80010a0 rank 0 nranks 1 cudaDev 0 busId af000 - Init COMPLETE
> initializing model parallel with size 1
> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
Traceback (most recent call last):
  File "finetune_glm.py", line 472, in <module>
    from tasks.superglue.finetune import main
  File "/dataset/lichunyou/GLM/GLM_copa/tasks/superglue/finetune.py", line 24, in <module>
    from tasks.eval_utils import accuracy_func_provider
  File "/dataset/lichunyou/GLM/GLM_copa/tasks/eval_utils.py", line 31, in <module>
    from sklearn.metrics import f1_score
ModuleNotFoundError: No module named 'sklearn'
Killing subprocess 2652666
Traceback (most recent call last):
  File "/dataset/lichunyou/conda_env/miniconda3/envs/p7/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/dataset/lichunyou/conda_env/miniconda3/envs/p7/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/dataset/lichunyou/conda_env/miniconda3/envs/p7/lib/python3.7/site-packages/deepspeed/launcher/launch.py", line 171, in <module>
    main()
  File "/dataset/lichunyou/conda_env/miniconda3/envs/p7/lib/python3.7/site-packages/deepspeed/launcher/launch.py", line 161, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/dataset/lichunyou/conda_env/miniconda3/envs/p7/lib/python3.7/site-packages/deepspeed/launcher/launch.py", line 139, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/dataset/lichunyou/conda_env/miniconda3/envs/p7/bin/python', '-u', 'finetune_glm.py', '--local_rank=0', '--deepspeed', '--deepspeed_config', 'config_tasks/config_blocklm_10B.json', '--finetune', '--cloze-eval', '--experiment-name', 'blank-base-copa_09-28-16-49', '--task', 'COPA', '--data-dir', '/dataset/lichunyou/GLM/GLM_copa/dataset/COPA', '--save', '/dataset/lichunyou/GLM/GLM_copa/copa_model', '--seq-length', '256', '--checkpoint-activations', '--eval-batch-size', '4', '--save-epoch', '100000', '--num-workers', '1', '--no-load-optim', '--no-load-lr-scheduler', '--block-lm', '--num-layers', '12', '--hidden-size', '768', '--num-attention-heads', '12', '--max-position-embeddings', '512', '--tokenizer-model-type', 'bert-base-uncased', '--tokenizer-type', 'BertWordPieceTokenizer', '--load-pretrained', '/dataset/lichunyou/GLM/GLM_copa/copa_model/blank-base-copa_08-25-23-55', '--lr-decay-style', 'linear', '--warmup', '0.1', '--weight-decay', '1.0e-1', '--pattern-id', '0', '--save-interval', '10000', '--log-interval', '20', '--eval-interval', '1000', '--eval-iters', '100', '--pattern-id', '0', '--fp16', '--model-parallel-size', '1', '--epochs', '-1', '--overwrite']' returned non-zero exit status 1.
